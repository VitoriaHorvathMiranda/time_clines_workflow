configfile: '../config/config.yaml'
include: 'rules/download_available_pools.smk'
include: 'rules/organize_pools.smk'
include: 'rules/map_all.smk'
include: 'rules/downsample.smk'
include: 'rules/pool_call.smk'
include: 'rules/analysis_GLM.smk'
include: 'rules/analysis_FST_PCA.smk'
include: 'rules/Inv_stats.smk'
include: 'rules/ancestry.smk'
include: 'rules/WorldClim_data.smk'
include: 'rules/get_ancestral_data.smk'

IDs = list(grouped_fqs.keys())
IDs_deleted_samples = [e for e in IDs if e not in ("17_L001", "09_L001")]
#PERM_N = [str(i) for i in range(1, 5040)] #5040 e não 5041 porque a primeira permutação são os latutudes certas
#expand(os.path.join(config['align_path'], "{ids}.md.srt.bam.bai"), ids = IDs)
rule all:
    input: expand(os.path.join(config['raw_fqs_path'], "{samples}_L001_R{r}.fastq.gz"), samples=config['SRAs_dict'].keys(), r=["1","2"]),
        "../results/depths_coverage_pre_pos_downsample.jpeg",
        os.path.join(config['call_path'], "PoolSNP_noSNC10_noESC97_with_dlGA10_dlSC10_mincount5_minfreq0.001_cov15_clean.h.vcf"),
        os.path.join(config['call_path'], "PoolSNP_noSNC10_noESC97_with_dlGA10_dlSC10_mincount5_minfreq0.001_cov15_clean.h.sync"),
        os.path.join(config['analysis_path'], "quality/Ti_Tv.tsv"),
        "../results/manhattan_97.jpeg",
        "../results/manhattan_0910.jpeg",
        "../results/P-values_hist.jpeg",
        "../results/PCA_all_pops.jpeg",
        "../results/PCA_per_time.jpeg",
        "../results/PCA_per_chrom_97.jpeg",
        "../results/PCA_per_chrom_0910.jpeg",
        "../resources/pool_sizes.csv",
        #"../results/thetapi_plot.jpeg",
        "../results/ALL_pops_genome_FST.jpeg",
        "../results/Time_pops_genome_FST.jpeg",
        expand("../results/manh_wfst_{local}_{window_size}.jpeg", local = config['pair_fst'], window_size=config['window_size_SNP']),
        expand("../results/manh_snp_{local}.jpeg", local = config['pair_fst']),
        "../results/hist_p-values_withPi.jpeg",
        "../results/q_Plot97.jpeg",
        "../results/q_Plot0910.jpeg",
        os.path.join(config['call_path'], "PoolSNP_noSNC10_noESC97_with_dlGA10_dlSC10_mincount5_minfreq0.001_cov15_clean.h.ann.vcf"),
        expand("../results/odds_ratio_{clinal_year}.jpeg", clinal_year = config['CLINAL_YEAR']),
        expand(os.path.join(config['analysis_path'], "time_GLM_lat/odds_ratio_{clinal_year}.tsv"), clinal_year = config['CLINAL_YEAR']),
        expand("../results/effect_summary_{clinal_year}.jpeg", clinal_year = config['CLINAL_YEAR']),
        "../results/Inv_freq_per_lat.jpeg",
        "../results/global_ancestry_per_lat.jpeg",
        "../results/all_global_ancestry_models_violin.jpeg",
        expand("../results/odds_ratio_to_integenic_{clinal_year}.jpeg",clinal_year = config['CLINAL_YEAR']),
        "../results/pop_stats_pi.jpeg", "../results/pop_stats_w.jpeg", "../results/pop_stats_D.jpeg",
        expand(os.path.join(config['analysis_path'], "pop_stats/truewindows_chrom_arm_{chrom_lenght_step}.txt"), chrom_lenght_step = config['chrom_lenght_step']),
        expand(os.path.join(config['analysis_path'], "fst/window/cutoff_{local}_{window_size}_{pair}.tsv"),
               local=["MA","CT","VT","MD","MFL"], window_size=["100", "250"],
               pair=lambda wildcards: get_pairs_from_file(os.path.join(config['analysis_path'], f"fst/window/cutoff_{wildcards.local}_{wildcards.window_size}.tsv"))
               ), ##PRECISA MUDAR PARA UM CHECKPOINT NO FUTURO
        #expand(os.path.join(config['analysis_path'], "time_GLM_lat/Perm/chance_perm_n_{perm_n}_{year}.tsv"), perm_n = PERM_N, year = ["97", "0910"])
        #expand(os.path.join(config['analysis_path'], "time_GLM_lat/GO_analysis/GO_enrichment_mode_{mode}_gendef_{gen_def}_only_clinal_{year}_at_{fdr}_fdr.tsv"), mode = ["gene","snp"], gen_def = ["updownstream1000"], year = config['CLINAL_YEAR'], fdr = config['FDR_cutoffs'])
        

#vou rodar primeiro até a tranferencia dos fastq de diretório. Isso porque, uma vez no diretório certo,
# o script do Roldan vai incluir as amostras baixadas na lista e no dicionario que ele cria.
#vai precisar mudar os wildcards_constrains no modulo map_all e organize para remover list(config['SRAs_dict'].keys())
#depois de rodar mudar a data dos index com:
#find . -name "*_downsample.md.srt.bam.bai" | while read filename; do touch -a -m -t 202405071505 $filename; done
